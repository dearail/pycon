# Learning Machine Morals

## Abstract

In a world that often approaches machine learning like a set of superpowers, Data Scientists become Supermen and women. As with Superman, with power, comes responsibility. The purpose of this paper is to start a discussion around   how that responsibility is defined at an individual and organizational level. We will develop some practical, Python based tools for putting responsibility into practice. The discussion is aimed at practitioners of machine learning at all levels; some familiarity with basic statistics and commonly used machine learning Python packages is useful. These practitioners will leave the talk with a better understanding of common ethical issues in machine learning, and useful practical tools for testing findings for reflections of fundamental assumptions, and demonstrating ethical bias in predictions on holdout sets.  Machine learning is sufficiently advanced that out of high volumes of noise we can now tailor predictions to very specific subsets of information. A common ethical issue in ML is the manipulation of rank ordered lists output by predictive models - particularly when weights are assigned according to a personal preference rather than objective criteria alone. Consider, for example, upweighting where a student falls in a university’s acceptance list based not just on their academic performance or potential, but also based on their families ability to make financial contributions to the institution. This has implications for everything from the way that search results are displayed when you query Google or Bing - a direct corollary to the current debate around net neutrality, to the way that preferences can be tailored in online dating, organ-donor matching, or hiring. 

## References

[Cowie]: Cowie, Roddy, and Marc Schröder. "Piecing together the emotion jigsaw." Machine Learning for Multimodal Interaction. Springer Berlin Heidelberg, 2005. 305-317.

[Johnson]: Johnson, Jeffrey Alan. "Ethics of data mining and predictive analytics in higher education." Association for Institutional Research Annual Forum, Long Beach, California. 2013.

[Fleischmann]: Fleischmann, Kenneth R., Thomas Clay Templeton, and Jordan Boyd-Graber. "Modeling diverse standpoints in text classification: Learning to be human by modeling human values." Proceedings of the 2011 iConference. ACM, 2011.

[Pasquale]: Pasquale, Frank A. "Internet nondiscrimination principles: commercial ethics for carriers and search engines." Seton Hall Public Law Research Paper1134159 (2008).